{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The concept for this model is to classify each stock into 5 categories and return a probability that a stock lands in a certain category.\n",
    "\n",
    "Possible Categories:\n",
    "1. Bullish - L\n",
    "2. Slightly Bullish - l\n",
    "3. Neutral - n\n",
    "4. Slightly Bearish - r\n",
    "5. Bearish - R\n",
    "\n",
    "<div>\n",
    "<img src=\"D_Classy_concept.png\" width=\"800\"/>\n",
    "</div>\n",
    "\n",
    "As you can see.  A stock will be classified by its maximum value during the action period.  The purpose of the action period is to allow our hypothesis to materialize.  Instead of predicting a discrete stock price at a discrete date, we will be predicting the peak performance during a set time frame.  \n",
    "\n",
    "This could be tuned later by adjusting number of categories and the characteristics of the action period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following packages and libraries will be necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge #1\n",
    "### Defining the training and testing data. \n",
    "---\n",
    "We will need sufficient data in order to train and test this model.  \n",
    " - Several stocks \n",
    " - Multiple sectors\n",
    " - Multiple market caps\n",
    "\n",
    "Each stock will require a diverse array of data to train on.  \n",
    " - Pricing Data\n",
    "    - High\n",
    "    - Low\n",
    "    - Close\n",
    "    - Volume\n",
    " - Company Fundamentals\n",
    "   - P/E\n",
    "   - ROI \n",
    "   - Quick Ratio\n",
    "   - etc.\n",
    " - Company Technicals\n",
    "    - SMA (several)\n",
    "    - RSI\n",
    "    - Beta\n",
    "    - etc.\n",
    " - Market Sentiment\n",
    "\n",
    "We could spend infinite time on this challenge... lets just start with our good friend Boeing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_span' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m [train_span, train_labels]      \u001b[39m# even years?\u001b[39;00m\n\u001b[0;32m      2\u001b[0m [test_span, test_labels]        \u001b[39m# odd years?\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_span' is not defined"
     ]
    }
   ],
   "source": [
    "[train_span, train_labels]      # even years?\n",
    "[test_span, test_labels]        # odd years?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge #2\n",
    "### Building the neural network\n",
    "---\n",
    "Currently we are using a very simple, fully connected NN.  This should be sufficient for proof of concept.\n",
    "\n",
    "Later strategies can include NEAT, RNNs and LSTM.\n",
    "\n",
    "First optimizer that we are going to use is adam. Adam is an algorithm that combines an Adaptive Gradient Algorithm with Root Mean Square Propogation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20 # Input layer needs to match the dimension of our input data.\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(n, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(5)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_span, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_span,  test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model we built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "\n",
    "predictions = probability_model.predict(test_span)\n",
    "\n",
    "predictions[0]\n",
    "\n",
    "np.argmax(predictions[0])\n",
    "\n",
    "test_labels[0]v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making our prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now is all data leading up to today\n",
    "predictions_single = probability_model.predict(now)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
